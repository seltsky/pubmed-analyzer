from groq import AsyncGroq
from app.config import GROQ_API_KEY
from app.models.schemas import Paper
from typing import Optional
import json


# ì „ë¬¸ë¶„ì•¼ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
SPECIALTY_PROMPTS = {
    "radiology": """ë‹¹ì‹ ì€ ì˜í•™ ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì¼ë°˜ì ì¸ ì˜ì‚¬ê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë…¼ë¬¸ì„ ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
ì—°êµ¬ì˜ ëª©ì , ë°©ë²•ë¡ , ì£¼ìš” ê²°ê³¼, ì„ìƒì  ì˜ì˜ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.""",

    "general": """ë‹¹ì‹ ì€ ì˜í•™ ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì—°êµ¬ì˜ ëª©ì , ë°©ë²•ë¡ , ì£¼ìš” ê²°ê³¼, ì„ìƒì  ì˜ì˜ë¥¼ ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”."""
}

# ì¸í„°ë²¤ì…˜ ì˜ìƒì˜í•™ê³¼ ì „ìš© ì¶”ê°€ ë¶„ì„
IR_INSIGHT_PROMPT = """
ì¶”ê°€ë¡œ, ì¸í„°ë²¤ì…˜ ì˜ìƒì˜í•™ê³¼(Interventional Radiology) ì „ë¬¸ì˜ ê´€ì ì—ì„œ ë‹¤ìŒ ì‚¬í•­ì´ ìˆë‹¤ë©´ ë¶„ì„í•´ì£¼ì„¸ìš”:
- ì˜ìƒ ìœ ë„ ì‹œìˆ  ê´€ë ¨ ë‚´ìš© (CT/US/Fluoro guided procedure)
- í˜ˆê´€ ì ‘ê·¼ë²•, ì¹´í…Œí„°/ì™€ì´ì–´ ì„ íƒ, ìƒ‰ì „ìˆ  ê¸°ë²•
- ì‹œìˆ  ì„±ê³µë¥ , í•©ë³‘ì¦, ê¸°ìˆ ì  ê³ ë ¤ì‚¬í•­
- ì¢…ì–‘ ì¹˜ë£Œ (TACE, RFA, MWA, Cryo ë“±) ê´€ë ¨ ë‚´ìš©
- í˜ˆê´€ ì¤‘ì¬ìˆ  (ìŠ¤í…íŠ¸, í˜ˆì „ì œê±°ìˆ , TIPS ë“±) ê´€ë ¨ ë‚´ìš©
- ë¹„í˜ˆê´€ ì¤‘ì¬ìˆ  (ë°°ì•¡ìˆ , ìƒê²€, ì²™ì¶”ì„±í˜•ìˆ  ë“±) ê´€ë ¨ ë‚´ìš©
í•´ë‹¹ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì´ ì„¹ì…˜ì€ "í•´ë‹¹ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”."""


async def summarize_paper(
    paper: Paper,
    language: str = "korean",
    specialty: str = "radiology"
) -> str:
    """ë‹¨ì¼ ë…¼ë¬¸ì˜ ì´ˆë¡ì„ ì „ë¬¸ë¶„ì•¼ì— ë§ê²Œ ìš”ì•½í•©ë‹ˆë‹¤."""

    if not GROQ_API_KEY:
        return "Groq API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    if not paper.abstract:
        return "ì´ˆë¡ì´ ì—†ìŠµë‹ˆë‹¤."

    client = AsyncGroq(api_key=GROQ_API_KEY)

    lang_instruction = "í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”." if language == "korean" else "Please write in English."
    specialty_prompt = SPECIALTY_PROMPTS.get(specialty, SPECIALTY_PROMPTS["general"])

    ir_section = IR_INSIGHT_PROMPT if specialty == "radiology" else ""

    prompt = f"""{specialty_prompt}

{lang_instruction}

## ë…¼ë¬¸ ì •ë³´
**ì œëª©**: {paper.title}
**ì €ë„**: {paper.journal}
**ì¶œíŒì¼**: {paper.pub_date}
**ì´ˆë¡**: {paper.abstract}

## ìš”ì•½ í˜•ì‹
ë‹¤ìŒ êµ¬ì¡°ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

### ğŸ“‹ ì—°êµ¬ ê°œìš”
(ì—°êµ¬ ëª©ì ê³¼ ë°°ê²½ì„ ê°„ê²°í•˜ê²Œ)

### ğŸ”¬ ì—°êµ¬ ë°©ë²•
(ëŒ€ìƒ, ì—°êµ¬ ì„¤ê³„, ë¶„ì„ ë°©ë²•)

### ğŸ“Š ì£¼ìš” ê²°ê³¼
(í•µì‹¬ ìˆ˜ì¹˜ì™€ í†µê³„ì  ìœ ì˜ì„±)

### ğŸ’¡ ì„ìƒì  ì˜ì˜
(ì‹¤ì œ ì§„ë£Œì— ì ìš©í•  ìˆ˜ ìˆëŠ” í¬ì¸íŠ¸)

### âš ï¸ ì œí•œì 
(ì—°êµ¬ì˜ í•œê³„, ìˆë‹¤ë©´)
{ir_section}
### ğŸ©º ì¸í„°ë²¤ì…˜ ì˜ìƒì˜í•™ê³¼ ê´€ì 
(ìœ„ ë¶„ì„ ë‚´ìš© ì‘ì„±)
"""

    response = await client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "user", "content": prompt}
        ],
        max_tokens=1000,
        temperature=0.3,
    )

    return response.choices[0].message.content or "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


async def summarize_multiple_papers(
    papers: list[Paper],
    language: str = "korean",
    specialty: str = "radiology"
) -> str:
    """ì—¬ëŸ¬ ë…¼ë¬¸ì˜ ê³µí†µ ì£¼ì œì™€ ê²°ë¡ ì„ ì „ë¬¸ë¶„ì•¼ì— ë§ê²Œ ì¢…í•© ìš”ì•½í•©ë‹ˆë‹¤."""

    if not GROQ_API_KEY:
        return "Groq API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    if not papers:
        return "ìš”ì•½í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."

    client = AsyncGroq(api_key=GROQ_API_KEY)

    lang_instruction = "í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”." if language == "korean" else "Please write in English."
    specialty_prompt = SPECIALTY_PROMPTS.get(specialty, SPECIALTY_PROMPTS["general"])

    # ë…¼ë¬¸ ì •ë³´ ì •ë¦¬
    papers_info = []
    for i, paper in enumerate(papers[:10], 1):
        abstract = paper.abstract[:600] if len(paper.abstract) > 600 else paper.abstract
        papers_info.append(
            f"**[ë…¼ë¬¸ {i}]**\n"
            f"- ì œëª©: {paper.title}\n"
            f"- ì €ë„: {paper.journal} ({paper.pub_date})\n"
            f"- ì´ˆë¡: {abstract}"
        )

    papers_text = "\n\n".join(papers_info)

    ir_section = IR_INSIGHT_PROMPT if specialty == "radiology" else ""

    prompt = f"""{specialty_prompt}

{lang_instruction}

## ë¶„ì„í•  ë…¼ë¬¸ ëª©ë¡ ({len(papers)}í¸)

{papers_text}

## ì¢…í•© ë¶„ì„ í˜•ì‹
ë‹¤ìŒ êµ¬ì¡°ë¡œ ì¢…í•© ë¶„ì„í•´ì£¼ì„¸ìš”:

### ğŸ“š ì—°êµ¬ ë™í–¥ ê°œìš”
(ì´ ë…¼ë¬¸ë“¤ì´ ë‹¤ë£¨ëŠ” ê³µí†µ ì£¼ì œì™€ ì—°êµ¬ íŠ¸ë Œë“œ)

### ğŸ” ì£¼ìš” ì—°êµ¬ ë°©ë²• ë¹„êµ
(í™˜ìêµ°, ì—°êµ¬ ì„¤ê³„, ë¶„ì„ ë°©ë²•ì˜ ê³µí†µì ê³¼ ì°¨ì´ì )

### ğŸ“Š í•µì‹¬ ë°œê²¬ ì¢…í•©
(ì—¬ëŸ¬ ì—°êµ¬ì—ì„œ ì¼ê´€ë˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²°ê³¼, ìƒì¶©ë˜ëŠ” ê²°ê³¼ê°€ ìˆë‹¤ë©´ ì–¸ê¸‰)

### ğŸ’¡ ì„ìƒ ì ìš© í¬ì¸íŠ¸
(ì˜ì‚¬ê°€ ì‹¤ë¬´ì—ì„œ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” í•µì‹¬ ì‚¬í•­)

### ğŸ”® í–¥í›„ ì—°êµ¬ ë°©í–¥
(í˜„ì¬ ì—°êµ¬ì˜ í•œê³„ì™€ í•„ìš”í•œ í›„ì† ì—°êµ¬)
{ir_section}
### ğŸ©º ì¸í„°ë²¤ì…˜ ì˜ìƒì˜í•™ê³¼ ê´€ì 
(ìœ„ ë¶„ì„ ë‚´ìš© ì‘ì„± - í•´ë‹¹ ë‚´ìš©ì´ ì—†ìœ¼ë©´ "í•´ë‹¹ ì—†ìŒ")
"""

    response = await client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "user", "content": prompt}
        ],
        max_tokens=1500,
        temperature=0.3,
    )

    return response.choices[0].message.content or "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


async def chat_with_papers(
    papers: list[Paper],
    user_message: str,
    chat_history: list[dict],
    language: str = "korean",
    specialty: str = "radiology"
) -> str:
    """ë…¼ë¬¸ ê¸°ë°˜ìœ¼ë¡œ AIì™€ ëŒ€í™”í•©ë‹ˆë‹¤."""

    if not GROQ_API_KEY:
        return "Groq API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    if not papers:
        return "ì„ íƒëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."

    client = AsyncGroq(api_key=GROQ_API_KEY)

    lang_instruction = "í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”." if language == "korean" else "Please answer in English."
    specialty_context = "ì‚¬ìš©ìëŠ” ì¸í„°ë²¤ì…˜ ì˜ìƒì˜í•™ê³¼ ì „ë¬¸ì˜ì…ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì˜í•™ ê´€ì ì—ì„œ ë‹µë³€í•˜ë˜, ì¸í„°ë²¤ì…˜ ì‹œìˆ (í˜ˆê´€/ë¹„í˜ˆê´€ ì¤‘ì¬ìˆ , ì˜ìƒìœ ë„ ì‹œìˆ  ë“±)ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´ ì¶”ê°€ë¡œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”." if specialty == "radiology" else ""

    # ë…¼ë¬¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    papers_context = []
    for i, paper in enumerate(papers[:10], 1):
        abstract = paper.abstract[:800] if len(paper.abstract) > 800 else paper.abstract
        papers_context.append(
            f"[ë…¼ë¬¸ {i}]\n"
            f"ì œëª©: {paper.title}\n"
            f"ì €ì: {', '.join(paper.authors[:5])}\n"
            f"ì €ë„: {paper.journal}\n"
            f"ì¶œíŒì¼: {paper.pub_date}\n"
            f"ì´ˆë¡: {abstract}"
        )

    context = "\n\n".join(papers_context)

    system_prompt = f"""ë‹¹ì‹ ì€ í•™ìˆ  ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì œê³µí•œ ë…¼ë¬¸ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.
{specialty_context}
{lang_instruction}

## ì œê³µëœ ë…¼ë¬¸ ì •ë³´:
{context}

## ë‹µë³€ ê°€ì´ë“œë¼ì¸:
- ì œê³µëœ ë…¼ë¬¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
- ë…¼ë¬¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  "ì œê³µëœ ë…¼ë¬¸ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”
- ê°€ëŠ¥í•˜ë©´ ì–´ë–¤ ë…¼ë¬¸ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì™”ëŠ”ì§€ ì–¸ê¸‰í•˜ì„¸ìš”
- ë‹µë³€ì€ ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- ì˜ìƒì˜í•™ì  ê´€ì ì—ì„œ ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”"""

    # ë©”ì‹œì§€ êµ¬ì„±
    messages = [{"role": "system", "content": system_prompt}]

    # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ìµœê·¼ 10ê°œ)
    for msg in chat_history[-10:]:
        messages.append({"role": msg["role"], "content": msg["content"]})

    # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    messages.append({"role": "user", "content": user_message})

    response = await client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=messages,
        max_tokens=1500,
        temperature=0.4,
    )

    return response.choices[0].message.content or "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


async def generate_search_query(natural_query: str, language: str = "korean") -> dict:
    """ìì—°ì–´ ê²€ìƒ‰ì–´ë¥¼ PubMed ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""

    if not GROQ_API_KEY:
        return {"error": "Groq API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    client = AsyncGroq(api_key=GROQ_API_KEY)

    prompt = f"""ë‹¹ì‹ ì€ PubMed ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ìµœì ì˜ PubMed ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

## ì‚¬ìš©ì ì§ˆë¬¸
"{natural_query}"

## ë³€í™˜ ê·œì¹™
1. í•µì‹¬ ì˜í•™ ìš©ì–´ë¥¼ ì˜ì–´ MeSH ìš©ì–´ë¡œ ë³€í™˜
2. ì ì ˆí•œ Boolean ì—°ì‚°ì (AND, OR) ì‚¬ìš©
3. í•„ìš”ì‹œ í•„ë“œ íƒœê·¸ ì‚¬ìš© ([Title/Abstract], [MeSH Terms] ë“±)
4. ë„ˆë¬´ ì¢ê±°ë‚˜ ë„“ì§€ ì•Šì€ ì ì ˆí•œ ë²”ìœ„ì˜ ì¿¼ë¦¬ ìƒì„±

## ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì´ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥)
QUERY: (ì‹¤ì œ PubMed ê²€ìƒ‰ ì¿¼ë¦¬)
EXPLANATION: (ì´ ì¿¼ë¦¬ë¥¼ ì„ íƒí•œ ì´ìœ , í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ)
KEYWORDS: (í•µì‹¬ í‚¤ì›Œë“œ 3-5ê°œ, ì‰¼í‘œë¡œ êµ¬ë¶„)

ì˜ˆì‹œ:
QUERY: (lung cancer[MeSH Terms]) AND (CT scan[Title/Abstract]) AND (diagnosis[MeSH Terms])
EXPLANATION: íì•”ì˜ CT ì§„ë‹¨ì— ê´€í•œ ë…¼ë¬¸ì„ ì°¾ê¸° ìœ„í•´ MeSH ìš©ì–´ì™€ ì œëª©/ì´ˆë¡ ê²€ìƒ‰ì„ ì¡°í•©í–ˆìŠµë‹ˆë‹¤.
KEYWORDS: lung cancer, CT, diagnosis, imaging"""

    response = await client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "user", "content": prompt}
        ],
        max_tokens=500,
        temperature=0.2,
    )

    result_text = response.choices[0].message.content or ""

    # ê²°ê³¼ íŒŒì‹±
    result = {
        "original_query": natural_query,
        "pubmed_query": "",
        "explanation": "",
        "keywords": []
    }

    for line in result_text.split("\n"):
        line = line.strip()
        if line.startswith("QUERY:"):
            result["pubmed_query"] = line.replace("QUERY:", "").strip()
        elif line.startswith("EXPLANATION:"):
            result["explanation"] = line.replace("EXPLANATION:", "").strip()
        elif line.startswith("KEYWORDS:"):
            keywords = line.replace("KEYWORDS:", "").strip()
            result["keywords"] = [k.strip() for k in keywords.split(",")]

    # ì¿¼ë¦¬ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
    if not result["pubmed_query"]:
        result["pubmed_query"] = natural_query

    return result


async def detect_ir_related_papers(papers: list[Paper]) -> dict[str, bool]:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¼ë¬¸ì´ ì¸í„°ë²¤ì…˜ ì˜ìƒì˜í•™ê³¼ì™€ ê´€ë ¨ìˆëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""

    if not GROQ_API_KEY or not papers:
        return {}

    client = AsyncGroq(api_key=GROQ_API_KEY)

    # ë…¼ë¬¸ ì •ë³´ë¥¼ ê°„ë‹¨íˆ ì •ë¦¬
    papers_info = []
    for paper in papers[:20]:  # ìµœëŒ€ 20ê°œ
        papers_info.append({
            "pmid": paper.pmid,
            "title": paper.title,
            "abstract": paper.abstract[:300] if paper.abstract else ""
        })

    papers_json = json.dumps(papers_info, ensure_ascii=False)

    prompt = f"""ë‹¹ì‹ ì€ ì¸í„°ë²¤ì…˜ ì˜ìƒì˜í•™ê³¼(Interventional Radiology) ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ë…¼ë¬¸ë“¤ì´ ì¸í„°ë²¤ì…˜ ì˜ìƒì˜í•™ê³¼ì™€ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

## IR ê´€ë ¨ ì£¼ì œ (ì´ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹ë˜ë©´ ê´€ë ¨ìˆìŒ):
- í˜ˆê´€ ì¤‘ì¬ìˆ : TACE, TARE, í˜ˆê´€ìƒ‰ì „ìˆ , ìŠ¤í…íŠ¸, TIPS, í˜ˆì „ì œê±°ìˆ , ë™ë§¥ë¥˜ ì¹˜ë£Œ
- ë¹„í˜ˆê´€ ì¤‘ì¬ìˆ : ê²½í”¼ì  ë°°ì•¡ìˆ , ìƒê²€, ì²™ì¶”ì„±í˜•ìˆ , ì‹ ê²½ì°¨ë‹¨ìˆ 
- ì¢…ì–‘ ì¹˜ë£Œ: RFA, MWA, ëƒ‰ë™ì ˆì œìˆ , IRE
- ì˜ìƒ ìœ ë„ ì‹œìˆ : CT/US/í˜•ê´‘íˆ¬ì‹œ ìœ ë„ ì‹œìˆ 
- í˜ˆê´€ ì ‘ê·¼: ì¹´í…Œí„°, ê°€ì´ë“œì™€ì´ì–´, ì²œì ê¸°ë²•
- ì¤‘ì¬ì  ì¢…ì–‘í•™: ê°„ì•”/ì‹ ì¥ì•”/íì•” ë“±ì˜ êµ­ì†Œì¹˜ë£Œ

## ë…¼ë¬¸ ëª©ë¡:
{papers_json}

## ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥):
{{"pmid1": true, "pmid2": false, ...}}

true = IR ê´€ë ¨, false = IR ê´€ë ¨ ì•„ë‹˜"""

    try:
        response = await client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=500,
            temperature=0.1,
        )

        result_text = response.choices[0].message.content or "{}"

        # JSON íŒŒì‹± ì‹œë„
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        start = result_text.find("{")
        end = result_text.rfind("}") + 1
        if start != -1 and end > start:
            json_str = result_text[start:end]
            return json.loads(json_str)

        return {}
    except Exception as e:
        print(f"IR ê°ì§€ ì˜¤ë¥˜: {e}")
        return {}
